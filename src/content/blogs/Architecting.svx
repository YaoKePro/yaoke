---
title: Architecting In The Age of AI
description: Maybe we should all stop typing code
date: 2025-06-13
edited: 2025-06-24
tags:
  - coding
  - AI
  - design
  - architecture
category: coding
---
The other day I watched an interview where the CEO of Microsoft, Satya Nadella was talking about how in the future software development will be less about writing code and more about higher level system design.

This is definitely one of the more grounded takes on AI's impact on coding. In my personal experience of using generative models such as ChatGPT, it's definitely not ready to completely replace human engineers yet, but it's certainly not useless.

So coming back to the titular claim, what has really changed in the world of programming? Should we strive to all become architects, or is handcrafting every UTF-8 symbol still mission critical?

In the following sections, I'll explore the different aspects of programming, and notate with + (it matters more now) and - (it matters less now) to paint my mental picture of programming in 2025.

## Syntax (-)

Syntax and language specific notations is becoming less and less important. In my experience of coding in Python, Java, C and Golang, I had already noticed that I was becoming more and more syntax agnostic. In the same family of languages (in this case the C family of languages), syntactic difference such as `func` vs `def` vs `function` matter less and less.

A proficient C programmer can just as easily understand Python code generated by AI given a bit of time to connect the dots. Now, more quickly than ever, can a Java programmer contribute to a C project.

## Language specific foot guns (+)

Whilst syntax is arguably less important, I would not be confident in saying languages are a thing of the past. This is due to the many nuances of particular languages which **must** be reasoned about carefully.

Everyone jokes about how Python is basically pseudocode, but it too has its unseeming language features. For instance, what could go wrong in the following code?

```python
def spawn_lst(init, lst = []):
	lst.append(init)
	return lst
```

 In Python, mutable default arguments are evaluated once and shared across function calls!

This means:

```python
x = spawn_lst(5) # == [5]
y = spawn_lst(6) # == [5, 6]

x is y # == True
```

However, to someone who doesn't have a strong grasp of Python, or more importantly, memory referencing and pointers, this can seem totally intangible and ridiculous.

But the bigger point is this, whilst syntactical differences for equivalent concepts have become trivial, not all languages are the same under the hood. Which leads me to my next point.

## Programming concepts (+)

What exactly is the important thing about languages and design in general? Concepts and ideas.

Design philosophies and understanding certain choices become more important than every. Golang refuses to have `class` whilst in Java, everything must be in a `class`. Swift uses automatic reference counting, C uses manual memory management whilst Python uses garbage collection. In Haskell, you can only code pure functions and all side effects must be wrapped in monads (a monoid in the category of endofunctors of course).

All of these higher level ideas become increasingly important to understand and master. They affect things beyond the fascade of syntax. They effect how you code and _why_ you code in certain patterns. Cue the time I copied generated React code and kept wondering why the state was not saved (I called useCustomHook twice ðŸ¤•).

## Style Guides (-)

Whilst style guides remain generally important for both human and AI readers, it's not as critical for the human programmer/architect to be aware of the best style for a particular language. This is simply because the AI will automatically adhere to the best style for you! With the addition of tools like linters and language servers, it's increasingly easier to write code with is of _perfect_ convention.

## Project Structure (+)

This involves perhaps one of the biggest limitations of LLMs, context window. An not just the raw advertised context window, but the true, effective context window (see [Nvidia's RULER](https://github.com/NVIDIA/RULER)). As such, breaking down large projects into components with well designed and exposed interfaces is crucial to scaling AI coding.

As such, I believe the most powerful AI coding tools in the future will intelligently manage the limited effective context window to design software component by component, with a sensible and well-designed overall architecture. The human will guide it along the way and each individual component will be reliable and self-contained.

## Tips for programmers

Perhaps it is time to shift away from the keyboard. I know, this sounds like sacrilege. But perhaps the flowchart diagram zealots were right all along.

There is of course no substitute for complete beginners typing out every character of the code just as a beginner in maths should learn to add and multiply by hand. But now we enter a new age where our new "calculator", generative AI, has dropped. Now we don't need to do the calculations by hand anymore. So what should we be doing instead?

I think pen and paper design, or something to that effect. But not just for behavioural diagrams and flow charts. Something in between code and specification. Something where implementation is shaping, but not concrete. Where structs are labelled in detail, constructors and destructors are well defined with responsibilities, and inheritance hierarchies are clear.

In other words, you paint the detailed skeleton of the code, and the AI fleshes it out. The more detailed the technical the skeleton, the better.

# Conclusion

Whilst typing every single character may be a thing of the past, high level understanding and concrete reasoning of design has never been more important. Having a solid grasp of key language concepts allow you to quickly get up to speed in any lanugage regardless of the syntax with AI generated code.

Understanding, integrating and designing said code will continue, in the forseeable future, be a challenging _human_ endeavour. 

Has this really changed since the past? We should strive to be better architects, but we always should've strived to be better architects. I guess the difference is now we have more time and ability to focus on architecting when the AI is doing the typing.

Typing line by line will be like sewing, a fun pastime for the nostalgic. I'll definitely be one.
